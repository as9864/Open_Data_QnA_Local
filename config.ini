;[CONFIG]
;mode = gcp
;embedding_model = vertex
;embedding_model_path =
;description_model = gemini-1.5-pro
;vector_store = bigquery-vector
;debugging = yes
;logging = yes
;kgq_examples = yes
;firestore_region = us-central1
;use_session_history = yes
;use_column_samples = no
;connector_backend = local
;
;[GCP]
;project_id = three-p-o
;
;[PGCLOUDSQL]
;pg_region = us-central1
;pg_instance = pg15-opendataqna
;pg_database = opendataqna-db
;pg_user = pguser
;pg_password = pg123
;
;[BIGQUERY]
;bq_dataset_region = us-central1
;bq_opendataqna_dataset_name = opendataqna
;bq_log_table_name = audit_log_table
;
;[LOCAL]
;pg_conn_string = postgresql://pguser:pg123@localhost:5432/opendataqna-db
;embedding_model_path = ./models/all-MiniLM-L6-v2
;llm_endpoint = http://localhost:8000/v1
;pg_conn = postgresql+psycopg2://user:pass@localhost:5432/opendataqna
;sqlite_db = opendataqna.db
[CONFIG]
; 실행 모드: 'local'로 지정
;mode = local

# 임베딩 모델
# 로컬 모델이라면 'embedding_model = huggingface' 또는 'vertex'가 아닌 다른 값 사용
embedding_model = huggingface
;embedding_model_path = ./models/all-MiniLM-L6-v2
;embedding_model_path = C:\Users\as907\.cache\huggingface\hub\models--google--gemma-2-2b
;[CONFIG]
MODE = local
EMBEDDING_MODEL_PATH = BAAI/bge-m3
#; 또는 BAAI/bge-small-en-v1.5, 로컬 경로 등

# 질의 설명용 LLM
# 로컬 LLM 서버를 사용한다면 내부 서버가 허용하는 모델명으로 변경
;description_model = llama3


description_model = off
# 벡터 스토어: 로컬 PostgreSQL + pgvector
vector_store = local-pgvector

# 디버깅/로그 설정
debugging = yes
logging = yes
kgq_examples = yes

# Firestore/BigQuery 사용 시 필요하지만 로컬 모드에서는 무시됨
firestore_region = us-central1

# 대화 기록/컬럼 샘플
;use_session_history = yes
use_session_history = False
use_column_samples = no

# 로컬 데이터 소스 (GCP 아닌 경우도 local로 유지)
connector_backend = local


[GCP]
# GCP 사용 시 채우지만, 로컬 환경이면 공란 또는 기본값 유지
project_id = three-p-o


[PGCLOUDSQL]
# GCP Cloud SQL을 쓰지 않는다면 무시
pg_region = us-central1
pg_instance = pg15-opendataqna
pg_database = opendataqna-db
pg_user = pguser
pg_password = pg123


[BIGQUERY]
# BigQuery를 사용하지 않을 경우 무시
bq_dataset_region = us-central1
bq_opendataqna_dataset_name = opendataqna
bq_log_table_name = audit_log_table


[OMOP]
concept_chat_model = gemini-1.5-pro


[LOCAL]
# 로컬 PostgreSQL 연결 정보
pg_conn_string = postgresql://postgres:secretpw@localhost:5433/opendataqna

# 임베딩 모델 위치
embedding_model_path = ./models/all-MiniLM-L6-v2

# 로컬 LLM 서버의 REST 엔드포인트
llm_endpoint = http://localhost:8000/v1

# SQLAlchemy용 연결 문자열 (SQLAlchemy를 활용하는 코드가 있을 때 사용)
PG_CONN = postgresql://postgres:secretpw@localhost:5433/opendataqna

# SQLite 파일 경로 (선택)
sqlite_db = opendataqna
pglocal = postgres
user_grouping = fhir_to_cdm
